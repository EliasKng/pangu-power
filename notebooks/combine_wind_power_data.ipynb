{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves to combine all downloaded nc files (1979 - 2023) to .zarr files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the onshore files is damaged (re-downloading didn't fix things). Therefore, April 2021 is excluded (file renamed .nc -> .nc_damaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the .nc files\n",
    "directory = \"/lsdf/kit/imk-tro/projects/Gruppe_Quinting/om1434/onshore\"\n",
    "\n",
    "# List all .nc files in the directory\n",
    "nc_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.nc')]\n",
    "\n",
    "# Open multiple .nc files into one dataset, concatenating along the time dimension\n",
    "dataset_by_coords = xr.open_mfdataset(nc_files, combine='by_coords')\n",
    "# dataset_nested = xr.open_mfdataset(nc_files, combine='nested', concat_dim='time')\n",
    "\n",
    "# Print the dataset to verify\n",
    "dataset_by_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "# Directory containing the .nc files\n",
    "directory = '/lsdf/kit/imk-tro/projects/Gruppe_Quinting/om1434/onshore'\n",
    "\n",
    "# List all .nc files in the directory\n",
    "nc_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.nc')]\n",
    "\n",
    "# Save the dataset to a .zarr file\n",
    "zarr_path = '/lsdf/kit/imk-tro/projects/Gruppe_Quinting/om1434/onshore/onshore.zarr'\n",
    "# TODO(EliasKng): era5.zarr is saved with time-chunk size of 1. Consider changing to the same.\n",
    "dataset_by_coords = dataset_by_coords.chunk({'time': 168, 'latitude': 185, 'longitude': 271})\n",
    "dataset_by_coords.to_zarr(zarr_path)\n",
    "\n",
    "print(f\"Dataset saved to {zarr_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one irregularity in the offshore data: between: 2019-12-31 and 2020-01-01.\n",
    "For 2019-12-31: 10pm and 11pm are missing. However since era5 data is 6hourly, this should not affect training (since we won't use those samples anyways)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "dataset = xr.open_dataset('/lsdf/kit/imk-tro/projects/Gruppe_Quinting/om1434/offshore/offshore.zarr')\n",
    "\n",
    "# Check for irregularities in the time dimension\n",
    "time_diff = dataset['time'].diff(dim='time')\n",
    "irregularities = time_diff[time_diff != np.timedelta64(1, 'h')]\n",
    "\n",
    "if irregularities.size > 0:\n",
    "    print(\"Irregularities found in the time dimension:\")\n",
    "    print(irregularities)\n",
    "    print(\"Exact date/time of irregularities:\")\n",
    "    print(irregularities['time'].values)\n",
    "else:\n",
    "    print(\"No irregularities found in the time dimension. The frequency is hourly.\")\n",
    "\n",
    "\n",
    "dataset.sel(time='2019-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset('/lsdf/kit/imk-tro/projects/Gruppe_Quinting/om1434/offshore/offshore.zarr', engine='zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5 = xr.open_dataset(\"/lsdf/kit/imk-tro/projects/Gruppe_Quinting/ec.era5/1959-2023_01_10-wb13-6h-1440x721.zarr\", engine='zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform power data and plot on a world map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"longitude\"] = dataset[\"longitude\"] % 360\n",
    "dataset = dataset.sortby(\"longitude\")\n",
    "target_dataset = dataset.sel(time=random_date + np.timedelta64(24, 'h'))\n",
    "target_dataset = target_dataset.reindex(\n",
    "    longitude=era5[\"longitude\"].values, \n",
    "    latitude=era5[\"latitude\"].values, \n",
    "    method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "target_dataset.wofcfr.plot(ax=ax, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "era5_random_date['2m_temperature'].plot(ax=ax, transform=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_amd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
