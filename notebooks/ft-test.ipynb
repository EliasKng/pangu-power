{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import logging\n",
    "import copy\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from tensorboardX import SummaryWriter\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"/home/hk-project-test-mlperf/om1434/masterarbeit/wind_fusion/pangu_pytorch\")\n",
    "\n",
    "# Import custom modules\n",
    "from era5_data import utils, utils_data\n",
    "from era5_data.utils_dist import get_dist_info, init_dist\n",
    "from era5_data.config import cfg\n",
    "from models.pangu_model import PanguModel\n",
    "from models.pangu_sample import test, train\n",
    "\n",
    "# Set up paths\n",
    "PATH = cfg.PG_INPUT_PATH\n",
    "output_path = os.path.join(cfg.PG_OUT_PATH, \"loratuner_normout\", str(cfg.PG.HORIZON))\n",
    "utils.mkdirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--type_net', type=str, default=\"loratuner_normout\")\n",
    "parser.add_argument('--load_pretrained', type=bool, default=False)\n",
    "parser.add_argument('--load_my_best', type=bool, default=True)\n",
    "parser.add_argument('--launcher', default='pytorch', help='job launcher')\n",
    "parser.add_argument('--local-rank', type=int, default=0)\n",
    "parser.add_argument('--dist', default=False)\n",
    "args = parser.parse_args([])  # Empty list to avoid errors in Jupyter\n",
    "\n",
    "# Device setup\n",
    "opt = {\"gpu_ids\": list(range(torch.cuda.device_count()))}  # Automatically select available GPUs\n",
    "gpu_list = ','.join(str(x) for x in opt['gpu_ids'])\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu_list\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Predicting on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributed settings\n",
    "if args.dist:\n",
    "    init_dist('pytorch')\n",
    "    rank, world_size = get_dist_info()\n",
    "    print(\"The rank and world size is\", rank, world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger and Summary Writer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger and Summary Writer setup\n",
    "writer_path = os.path.join(output_path, \"writer\")\n",
    "if not os.path.exists(writer_path):\n",
    "    os.mkdir(writer_path)\n",
    "\n",
    "writer = SummaryWriter(writer_path)\n",
    "\n",
    "logger_name = args.type_net + str(cfg.PG.HORIZON)\n",
    "utils.logger_info(logger_name, os.path.join(output_path, logger_name + '.log'))\n",
    "\n",
    "logger = logging.getLogger(logger_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader setup\n",
    "train_dataset = utils_data.NetCDFDataset(nc_path=PATH,\n",
    "                                         data_transform=None,\n",
    "                                         training=True,\n",
    "                                         validation=False,\n",
    "                                         startDate=cfg.PG.TRAIN.START_TIME,\n",
    "                                         endDate=cfg.PG.TRAIN.END_TIME,\n",
    "                                         freq=cfg.PG.TRAIN.FREQUENCY,\n",
    "                                         horizon=cfg.PG.HORIZON)\n",
    "\n",
    "if args.dist:\n",
    "    train_sampler = DistributedSampler(train_dataset, shuffle=True, drop_last=True)\n",
    "    train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=cfg.PG.TRAIN.BATCH_SIZE,\n",
    "                                       num_workers=0, pin_memory=False, sampler=train_sampler)\n",
    "else:\n",
    "    train_dataloader = data.DataLoader(dataset=train_dataset,\n",
    "                                       batch_size=cfg.PG.TRAIN.BATCH_SIZE,\n",
    "                                       drop_last=True, shuffle=True, num_workers=0, pin_memory=False)\n",
    "\n",
    "dataset_length = len(train_dataloader)\n",
    "print(\"dataset_length\", dataset_length)\n",
    "\n",
    "val_dataset = utils_data.NetCDFDataset(nc_path=PATH,\n",
    "                                       data_transform=None,\n",
    "                                       training=False,\n",
    "                                       validation=True,\n",
    "                                       startDate=cfg.PG.VAL.START_TIME,\n",
    "                                       endDate=cfg.PG.VAL.END_TIME,\n",
    "                                       freq=cfg.PG.VAL.FREQUENCY,\n",
    "                                       horizon=cfg.PG.HORIZON)\n",
    "\n",
    "val_dataloader = data.DataLoader(dataset=val_dataset, batch_size=cfg.PG.VAL.BATCH_SIZE,\n",
    "                                 drop_last=True, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "test_dataset = utils_data.NetCDFDataset(nc_path=PATH,\n",
    "                                        data_transform=None,\n",
    "                                        training=False,\n",
    "                                        validation=False,\n",
    "                                        startDate=cfg.PG.TEST.START_TIME,\n",
    "                                        endDate=cfg.PG.TEST.END_TIME,\n",
    "                                        freq=cfg.PG.TEST.FREQUENCY,\n",
    "                                        horizon=cfg.PG.HORIZON)\n",
    "\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=cfg.PG.TEST.BATCH_SIZE,\n",
    "                                  drop_last=True, shuffle=False, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup and Loading Pretrained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup and loading pretrained weights\n",
    "model = PanguModel(device=device).to(device)\n",
    "checkpoint = torch.load(cfg.PG.BENCHMARK.PRETRAIN_24_torch, map_location=device, weights_only=True)\n",
    "print('loading model pretrained weight.')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "print([(n, type(m)) for n, m in model.named_modules()])\n",
    "target_modules = []\n",
    "for n, m in model.named_modules():\n",
    "    if isinstance(m, nn.Linear):\n",
    "        target_modules.append(n)\n",
    "        print(f\"appended {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Configuration and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration and model preparation\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.1, # Change to 0.01 ? (since we have a lot of data)\n",
    "    modules_to_save=[\"_output_layer.conv_surface\", \"_output_layer.conv\"]\n",
    ")\n",
    "\n",
    "module_copy = copy.deepcopy(model)  # Keep a copy of the original model for later\n",
    "\n",
    "peft_model = get_peft_model(model, config)\n",
    "optimizer = torch.optim.Adam(peft_model.parameters(), lr=cfg.PG.TRAIN.LR, weight_decay=cfg.PG.TRAIN.WEIGHT_DECAY)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 50], gamma=0.5)\n",
    "start_epoch = 1\n",
    "\n",
    "if args.load_pretrained:\n",
    "    cpk = torch.load(os.path.join(output_path, \"models/train_30.pth\"))\n",
    "    peft_model.load_state_dict(cpk['model'])\n",
    "    optimizer.load_state_dict(cpk['optimizer'])\n",
    "    lr_scheduler.load_state_dict(cpk['lr_scheduler'])\n",
    "    start_epoch = cpk[\"epoch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "peft_model = train(peft_model, train_loader=train_dataloader,\n",
    "                   val_loader=val_dataloader,\n",
    "                   optimizer=optimizer,\n",
    "                   lr_scheduler=lr_scheduler,\n",
    "                   res_path=output_path,\n",
    "                   device=device,\n",
    "                   writer=writer, logger=logger, start_epoch=start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Updated Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking updated parameters\n",
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<13} | {param.numel():>5} parameters | updated\")\n",
    "\n",
    "params_before = dict(module_copy.named_parameters())\n",
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" in name:\n",
    "        continue\n",
    "\n",
    "    name_before = name.partition(\".\")[-1].replace(\"original_\", \"\").replace(\"module.\", \"\").replace(\n",
    "        \"modules_to_save.default.\", \"\")\n",
    "    param_before = params_before[name_before]\n",
    "    if torch.allclose(param, param_before):\n",
    "        print(f\"Parameter {name_before:<13} | {param.numel():>7} parameters | not updated\")\n",
    "    else:\n",
    "        print(f\"Parameter {name_before:<13} | {param.numel():>7} parameters | updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "output_path = os.path.join(output_path, \"test\")\n",
    "utils.mkdirs(output_path)\n",
    "\n",
    "test(test_loader=test_dataloader,\n",
    "     model=peft_model,\n",
    "     device=device,\n",
    "     res_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_amd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
